{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Icosa Computing Combinatorial Reasoning Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have uploaded the package to PyPi, so the combinatorial reasoning pipeline can be accessed very easily via a pip install."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install langchain_icosa # download package if not already installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_icosa.combinatorial_reasoning import CombinatorialReasoningLLM, CombinatorialReasoningCallbackHandler\n",
    "from langchain_icosa.combinatorial_reasoning import CombinatorialReasoningLLM, CombinatorialReasoningCallbackHandler\n",
    "from langchain_openai import ChatOpenAI # this is our zero-shot comparison\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from getpass import getpass\n",
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = getpass('Enter OpenAI API key')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison of Zero-Shot and CR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use `GPT-3.5-Turbo` for the base LLM. \n",
    "\n",
    "The actual compute of the Combinatorial Reasoning pipeline takes place off-premises on Icosa's cloud servers, which enables the library to be installed with fewer external dependencies and performance requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ZeroShotLLM = ChatOpenAI(openai_api_key=API_KEY, model = 'gpt-3.5-turbo')\n",
    "CrLLM = CombinatorialReasoningLLM(openai_api_key=API_KEY, model = 'gpt-3.5-turbo')\n",
    "callback = CombinatorialReasoningCallbackHandler() # callback to hook into the reason selection process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Combinatorial Reasoning LLM supports user-adjustable hyperparameters. However, we have already tuned these hyperparameters, and so for almost all use cases, the default parameters are sufficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(CrLLM.dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Combinatorial Reasoning LLM supports answers with and without reasoning, adjustable via the `responseType` parameter in the invoke method. This method also supports overloading the hyperparameters. For the sake of demonstration, we include the reasoning in all responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_llms(prompt, seed = 0): \n",
    "    display(Markdown(f\"### Prompt\\n{prompt}\"))\n",
    "    zero_shot_solution = ZeroShotLLM.invoke(prompt).content\n",
    "    display(Markdown(\"### Zero-Shot Solution\"))\n",
    "    display(Markdown(zero_shot_solution))\n",
    "    cr_solution = CrLLM.invoke(prompt, responseType='answerWithReasoning', seed = seed, config={'callbacks': [callback]})\n",
    "    display(Markdown(\"### CR Solution\"))\n",
    "    display(Markdown(cr_solution))\n",
    "    display(Markdown(\"### CR Statistics\"))\n",
    "    formatted_stats = (\n",
    "        f\"- **Number of Distinct Reasons**: {callback.stats[0]['num_distinct_reasons']}\\n\" +\n",
    "        f\"- **Number of Selected Reasons**: {callback.stats[0]['num_selected_reasons']}\\n\" + \n",
    "        f\"- **Percentage Selected**: {callback.stats[0]['proportion_selected']:.2%}\"\n",
    "    )\n",
    "    display(Markdown(formatted_stats))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_reasons():\n",
    "    display(Markdown(\"### Final Selected Reasons\"))\n",
    "    selected_reasons = callback.data['selected_reasons'][0]\n",
    "    formmated_reasons = \"\\n- \".join([f\"{reason[0]}\" for reason in selected_reasons])\n",
    "    display(Markdown(\"- \" + formmated_reasons))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Animal Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animal_prompt = \"There are six animals: lion, hyena, elephant, deer, cat and mouse. Separate them to three spaces to minimize conflict.\"\n",
    "compare_llms(animal_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## River Crossing Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "river_prompt = '''\n",
    "There is a man, a sheep and a boat with space for one human and one animal on one side of a river. How do the man and sheep get to the other side of the river?\n",
    "'''\n",
    "compare_llms(river_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trolley Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trolley_prompt = '''\n",
    "\"Imagine a runaway trolley is hurtling down a track towards five dead people. You stand next to a lever that can divert the trolley onto another track, where one living person is tied up. Do you pull the lever?\"\n",
    "'''\n",
    "compare_llms(trolley_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage with LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate.from_template(\"Should I buy {ticker} stock today?\")\n",
    "model = CombinatorialReasoningLLM(openai_api_key=API_KEY)\n",
    "chain = prompt | model | StrOutputParser()\n",
    "\n",
    "chain.invoke({'ticker': 'AAPL'})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
